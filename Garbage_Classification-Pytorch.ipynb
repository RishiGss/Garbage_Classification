{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms=transforms.Compose([transforms.Resize((300,300)),\n",
    "                              transforms.RandomHorizontalFlip(p=0.5),\n",
    "                              transforms.ToTensor()\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='./train_valid_test/train/'\n",
    "valid_dir='./train_valid_test/valid/'\n",
    "test_dir='./train_valid_test/test/'\n",
    "\n",
    "train_loader=DataLoader(dset.ImageFolder(train_dir,transform=img_transforms),\n",
    "                                        batch_size=64,shuffle=True)\n",
    "\n",
    "valid_loader=DataLoader(dset.ImageFolder(valid_dir,transform=img_transforms),\n",
    "                                        batch_size=64,shuffle=False)\n",
    "\n",
    "test_loader=DataLoader(dset.ImageFolder(test_dir,transform=img_transforms),\n",
    "                                        batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['cardboard','glass','metal','paper','plastic','trash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count=len(glob.glob(train_dir+'/**/*.jpg'))\n",
    "valid_count=len(glob.glob(valid_dir+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_dir+'/**/*.jpg'))\n",
    "print(\"No of  images in\\n\\tTraining set : \",train_count,\"\\n\\tValidation set : \",valid_count,\"\\n\\tTest set : \",test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network\n",
    "class GarbageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarbageNet,self).__init__()\n",
    "        #(64,3,300,300)\n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3,padding=1), #(64,32,300,300)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2), #(64,32,150,150)\n",
    "            nn.Dropout(),\n",
    "        \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), #(64,64,148,148)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2), #(64,64,74,74)\n",
    "        \n",
    "            nn.Conv2d(in_channels=64, out_channels=16, kernel_size=3), #(64,16,72,72)\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2), #(64,16,36,36)\n",
    "            nn.Dropout(),\n",
    "    \n",
    "        )\n",
    "        \n",
    "        self.fc1=nn.Linear(16*36*36,256)\n",
    "        self.fc2=nn.Linear(256,6)\n",
    "        \n",
    "    def forward(self,img):\n",
    "        img=self.conv(img)\n",
    "        img=img.view(-1,16*36*36)\n",
    "        img=self.fc1(img)\n",
    "        img=self.fc2(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and loss function\n",
    "net=GarbageNet().to(device)\n",
    "optimizer=optim.Adam(net.parameters(),lr=0.001, weight_decay=0.001)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of parameters in the network\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(GarbageNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation\n",
    "epochs=30\n",
    "\n",
    "def train_valid(net, train_loader, valid_loader, epochs, criterion):\n",
    "    train_loss=[] # training loss for every epoch\n",
    "    valid_loss=[] # validation loss for every epoch\n",
    "    train_accuracy=[]\n",
    "    valid_accuracy=[]\n",
    "    sum_train_loss=0.0 # sum of training losses for every epoch\n",
    "    sum_valid_loss=0.0 # sum of validation losses for every epoch\n",
    "    sum_train_accuracy=0.0\n",
    "    sum_valid_accuracy=0.0\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "    \n",
    "        train_epoch_loss=0.0\n",
    "        train_epoch_accuracy=0.0\n",
    "        net.train()\n",
    "        for i,(images, labels) in enumerate(train_loader):\n",
    "            images, labels =images.to(device), labels.to(device)\n",
    "            output = net(images)\n",
    "            loss = criterion(output, labels)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_epoch_loss = train_epoch_loss + ((1/(i+1)) * (loss.item() - train_epoch_loss))\n",
    "            \n",
    "            #_,pred_label = torch.max(output.data,1)\n",
    "            pred_softmax=torch.softmax(output,1)\n",
    "            _,prediction = torch.max(pred_softmax,1)\n",
    "            #train_epoch_accuracy+=int(torch.sum(pred_label==labels.data))\n",
    "            train_epoch_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "        train_epoch_accuracy=train_epoch_accuracy/train_count\n",
    "\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        sum_train_loss+=train_epoch_loss\n",
    "        \n",
    "        train_accuracy.append(train_epoch_accuracy)\n",
    "        sum_train_accuracy+=train_epoch_accuracy\n",
    "    \n",
    "        valid_epoch_loss=0.0\n",
    "        valid_epoch_accuracy=0.0\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for i,(images, labels) in enumerate(valid_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                output = net(images)\n",
    "                loss = criterion(output, labels)\n",
    "                \n",
    "                valid_epoch_loss = valid_epoch_loss + ((1/(i+1)) * (loss.item() - valid_epoch_loss))\n",
    "                #_,predlabel = torch.max(output.data,1)\n",
    "                pred_softmax=torch.softmax(output,1)\n",
    "                _,prediction = torch.max(pred_softmax,1)\n",
    "                #valid_epoch_accuracy+=int(torch.sum(predlabel==labels.data))\n",
    "                valid_epoch_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "        valid_epoch_accuracy=valid_epoch_accuracy/valid_count\n",
    "                \n",
    "        valid_loss.append(valid_epoch_loss)\n",
    "        sum_valid_loss+=valid_epoch_loss\n",
    "        \n",
    "        valid_accuracy.append(valid_epoch_accuracy)\n",
    "        sum_valid_accuracy+=valid_epoch_accuracy\n",
    "        \n",
    "        print(\"Epoch {}/{}\\n Train loss : {} \\t Valid loss {}\\n Train accuracy : {} \\t Valid accuracy : {}\\n\"\n",
    "             .format(epoch, epochs, train_epoch_loss, valid_epoch_loss,train_epoch_accuracy, valid_epoch_accuracy))\n",
    "        \n",
    "    print(\"Average training loss after {} epochs : {}\".format(epochs, sum_train_loss/epochs))\n",
    "    print(\"Average validation loss after {} epochs : {}\\n\".format(epochs, sum_valid_loss/epochs))\n",
    "    print(\"Average training accuracy after {} epochs : {}\".format(epochs, sum_train_accuracy/epochs))\n",
    "    print(\"Average validation accuracy after {} epochs : {}\".format(epochs, sum_valid_accuracy/epochs))\n",
    "    \n",
    "    return train_loss, valid_loss, train_accuracy, valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, valid_losses, train_acc, valid_acc = train_valid(net, train_loader, valid_loader, epochs, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loss and accuracy plot\n",
    "def plot_imshow(xlabel, ylabel, plot1, plot1lab, plot2, plot2lab):\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(plot1, label=plot1lab)\n",
    "    plt.plot(plot2, label=plot2lab)\n",
    "    plt.legend(bbox_to_anchor=(1.1,1.0), loc='upper left')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training loss and validation loss\n",
    "print(\"Training loss and Validation loss plot\")\n",
    "plot_imshow('epochs', 'loss',train_losses, \"Train loss\", valid_losses, \"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training accuracy and validation accuracy\n",
    "print(\"Training accuracy and Validation accuracy plot\")\n",
    "plot_imshow('epochs', 'accuracy',train_acc, \"Train accuracy\", valid_acc, \"Validation accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def eval(net, test_loader):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        count=100\n",
    "        correct=0\n",
    "        correct_count=0\n",
    "        dataiter = iter(test_loader)\n",
    "        \n",
    "        print(\"Testing...\")\n",
    "        for i in range(count):\n",
    "            img, label = next(dataiter)\n",
    "            image=img\n",
    "            output = net(Variable(img).cuda())\n",
    "            pred_softmax=torch.softmax(output,1)\n",
    "            _,prediction = torch.max(pred_softmax,1)\n",
    "            #print(prediction)\n",
    "            total = label.size(0)\n",
    "\n",
    "            # check if prediction and actual label are same\n",
    "            for j in range(output.size(0)):\n",
    "                if (prediction[j]==label[j]):\n",
    "                    correct+=1\n",
    "                \n",
    "            correct_count+=correct/total\n",
    "            correct=0\n",
    "            imshow(torchvision.utils.make_grid(image),'Pred : {}  Label : {}'.format(classes[prediction.item()],classes[label.item()]))   \n",
    "        \n",
    "    return correct_count, count, (correct_count/count)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=eval(net, test_loader)\n",
    "print('{} correct predictions out of {}\\nAccuracy : {:.2f}'.format(acc[0],acc[1], acc[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
